{"ts":1375132334746,"silentsave":true,"restoring":false,"patch":[[{"diffs":[[1,"var nodeio = require('node.io');\nvar util = require('util');\n\nexports.scrape = function (scrapeOptions, callback) {\n  var job = new nodeio.Job({\n    input: [ scrapeOptions ],\n    run: function (input) {\n\n      // url to scrape\n      var url = scrapeOptions.url;\n      console.log('url: ' + scrapeOptions.url);       \n\n      this.getHtml(url, function(err, $) {\n        //Handle any request / parsing errors\n        if (err) { \n          console.log(\"Unable to parse site:\");\n          this.exit(err);\n        }\n\n        // get all the listings on the page\n        var rows = {};\n\n        console.log('selector: ' + scrapeOptions.rowSelector);\n        var results = $(scrapeOptions.rowSelector);\n\n        // storing this as a function to work around node.io's decision not to return\n        // selectors that match only 1 item as an array of 1 item (which makes .each() not \n        // work when only item is returned)\n        var scraper = function(listing) {\n          var row = {};\n          var lastId;\n\n          var colNumber = 0;\n          for (var col in scrapeOptions.outputMappings)\n          { \n            console.log('scraping: ' + scrapeOptions.outputMappings[col].selector);\n            \n            // if the column cant be scraped, continue anyway\n            try {\n              var data = $(scrapeOptions.outputMappings[col].selector,listing)[scrapeOptions.outputMappings[col].accessor]; //[\"attribs.href\"]; \n\n              // remember the id so we can use it as the key\n              if (colNumber === 0) { \n                lastId = data;\n              }\n              // store all other columns as properties\n              else {\n                row[col] =  data;\n              } \n\n              rows[lastId] = row;\n            }\n            catch (e)\n            {\n\n            }\n            colNumber++;\n          }\n        };\n\n        if (results.length === undefined) {\n          scraper(results);\n        }\n        else {\n          results.each(scraper);\n        }\n        \n\n        this.emit(rows);\n      });\n}\n});\nnodeio.start(job, { silent: true }, callback, true);\n};\n\n"]],"start1":0,"start2":0,"length1":0,"length2":2098}]],"length":2098}
{"contributors":[],"silentsave":false,"ts":1375200553293,"patch":[[{"diffs":[[0,"Options,"],[1," outputMappings,"],[0," callbac"]],"start1":95,"start2":95,"length1":16,"length2":32},{"diffs":[[0," col in "],[-1,"scrapeOptions."],[0,"outputMa"]],"start1":1070,"start2":1070,"length1":30,"length2":16},{"diffs":[[0,"ng: ' + "],[-1,"scrapeOptions."],[0,"outputMa"]],"start1":1138,"start2":1138,"length1":30,"length2":16},{"diffs":[[0,"ata = $("],[-1,"scrapeOptions."],[0,"outputMa"]],"start1":1289,"start2":1289,"length1":30,"length2":16},{"diffs":[[0,"isting)["],[-1,"scrapeOptions."],[0,"outputMa"]],"start1":1327,"start2":1327,"length1":30,"length2":16}]],"length":2058,"saved":false}
